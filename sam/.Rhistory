xlab   = "Number of Lynx Trapped")
# Add a normal distribution
curve(dnorm(x, mean = mean(lynx), sd = sd(lynx)),
col = "thistle4",  # Color of curve
lwd = 2,           # Line width of 2 pixels
add = TRUE)        # Superimpose on previous graph
# Add two kernel density estimators
lines(density(lynx), col = "blue", lwd = 2)
lines(density(lynx, adjust = 3), col = "purple", lwd = 2)
# Add a rug plot
rug(lynx, lwd = 2, col = "gray")
# Clear packages
detach("package:datasets", unload = TRUE)  # For base
# Clear plots
dev.off()  # But only if there IS a plot
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load/unload base packages manually
head(iris)
summary(iris$Species)       # Categorical variable
summary(iris$Sepal.Length)  # Quantitative variable
summary(iris)               # Entire data frame
# Clear packages
detach("package:datasets", unload = TRUE)   # For base
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load base packages manually
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, psych)
head(iris)
# Get info on package
p_help(psych)           # Opens package PDF in browser
p_help(psych, web = F)  # Opens help in R Viewer
describe(iris$Sepal.Length)  # One quantitative variable
describe(iris)               # Entire data frame
# Clear environment
rm(list = ls())
# Clear packages
p_unload(all)  # Remove all add-ons
detach("package:datasets", unload = TRUE)   # For base
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load/unload base packages manually
head(iris)
hist(iris$Petal.Length)
summary(iris$Petal.Length)
summary(iris$Species)  # Get names and n for each species
# Versicolor
hist(iris$Petal.Length[iris$Species == "versicolor"],
main = "Petal Length: Versicolor")
# Virginica
hist(iris$Petal.Length[iris$Species == "virginica"],
main = "Petal Length: Virginica")
# Setosa
hist(iris$Petal.Length[iris$Species == "setosa"],
main = "Petal Length: Setosa")
# Short petals only (all Setosa)
hist(iris$Petal.Length[iris$Petal.Length < 2],
main = "Petal Length < 2")
# Short Virginica petals only
hist(iris$Petal.Length[iris$Species == "virginica" &
iris$Petal.Length < 5.5],
main = "Petal Length: Short Virginica")
# Format: data[rows, columns]
# Leave rows or columns blank to select all
i.setosa <- iris[iris$Species == "setosa", ]
head(i.setosa)
summary(i.setosa$Petal.Length)
hist(i.setosa$Petal.Length)
# Clear environment
rm(list = ls())
# Clear packages
detach("package:datasets", unload = TRUE)  # For base
# Clear plots
dev.off()  # But only if there IS a plot
# Clear console
cat("\014")  # ctrl+L
n1 <- 15  # Double precision by default
n1
typeof(n1)
n2 <- 1.5
n2
typeof(n2)
c1 <- "c"
c1
typeof(c1)
c2 <- "a string of text"
c2
typeof(c2)
l1 <- TRUE
l1
typeof(l1)
l2 <- F
l2
typeof(l2)
v1 <- c(1, 2, 3, 4, 5)
v1
is.vector(v1)
v2 <- c("a", "b", "c")
v2
is.vector(v2)
v3 <- c(TRUE, TRUE, FALSE, FALSE, TRUE)
v3
is.vector(v3)
m1 <- matrix(c(T, T, F, F, T, F), nrow = 2)
m1
m2 <- matrix(c("a", "b",
"c", "d"),
nrow = 2,
byrow = T)
m2
# Give data, then dimemensions (rows, columns, tables)
a1 <- array(c( 1:24), c(4, 3, 2))
a1
vNumeric   <- c(1, 2, 3)
vCharacter <- c("a", "b", "c")
vLogical   <- c(T, F, T)
dfa <- cbind(vNumeric, vCharacter, vLogical)
dfa  # Matrix of one data type
df <- as.data.frame(cbind(vNumeric, vCharacter, vLogical))
df  # Makes a data frame with three different data types
o1 <- c(1, 2, 3)
o2 <- c("a", "b", "c", "d")
o3 <- c(T, F, T, T, F)
list1 <- list(o1, o2, o3)
list1
list2 <- list(o1, o2, o3, list1)  # Lists within lists!
list2
(coerce1 <- c(1, "b", TRUE))
# coerce1  # Parenthese around command above make this moot
typeof(coerce1)
(coerce2 <- 5)
typeof(coerce2)
(coerce3 <- as.integer(5))
typeof(coerce3)
(coerce4 <- c("1", "2", "3"))
typeof(coerce4)
(coerce5 <- as.numeric(c("1", "2", "3")))
typeof(coerce5)
(coerce6 <- matrix(1:9, nrow= 3))
is.matrix(coerce6)
(coerce7 <- as.data.frame(matrix(1:9, nrow= 3)))
is.data.frame(coerce7)
# Clear environment
rm(list = ls())
# Clear console
cat("\014")  # ctrl+L
(x1 <- 1:3)
(y  <- 1:9)
# Combine variables
(df1 <- cbind.data.frame(x1, y))
typeof(df1$x1)
str(df1)
(x2  <- as.factor(c(1:3)))
(df2 <- cbind.data.frame(x2, y))
typeof(df2$x2)
str(df2)
x3  <- c(1:3)
df3 <- cbind.data.frame(x3, y)
(df3$x3 <- factor(df3$x3,
levels = c(1, 2, 3)))
typeof(df3$x3)
str(df3)
x4  <- c(1:3)
df4 <- cbind.data.frame(x4, y)
df4$x4 <- factor(df4$x4,
levels = c(1, 2, 3),
labels = c("macOS", "Windows", "Linux"))
df4
typeof(df4$x4)
str(df4)
x5  <- c(1:3)
df5 <- cbind.data.frame(x5, y)
(df5$x5 <- ordered(df5$x5,
levels = c(3, 1, 2),
labels = c("No", "Maybe", "Yes")))
df5
typeof(df5$x5)
str(df5)
# Clear environment
rm(list = ls())
# Clear console
cat("\014")  # ctrl+L
# Clear console
cat("\014")  # ctrl+L
# Assigns number 0 through 10 to x1
x1 <- 0:10
x1
# Descending order
x2 <- 10:0
x2
?seq  # R help on seq
# Ascending values (duplicates 1:10)
(x3 <- seq(10))
# Specify change in values
(x4 <- seq(30, 0, by = -3))
# c = concatenate (or combine or collect)
?c  # R help on c
x5 <- c(5, 4, 1, 6, 7, 2, 2, 3, 2, 8)
x5
?scan  # R help on scan
x6 <- scan()  # After running this command, go to console
# Hit return after each number
# Hit return twice to stop
x6
?rep  # R help on rep
x7 <- rep(TRUE, 5)
x7
# Repeats set
x8 <- rep(c(TRUE, FALSE), 5)
x8
# Repeats items in set
x9 <- rep(c(TRUE, FALSE), each = 5)
x9
# Clear environment
rm(list = ls())
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load base packages manually
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, rio)
# From the official R documentation
browseURL("http://j.mp/2aFZUrJ")
# CSV
rio_csv <- import("~/Desktop/mbb.csv")
# CSV
rio_csv <- import("~/Desktop/mbb.csv")
getwd()
setwd("C:/Users/srobi/Desktop/R01_Course_Files/R01_5_4_ImportingData_Datasets")
getwd()
# CSV
rio_csv <- import("mbb.csv")
head(rio_csv)
# TXT
rio_txt <- import("mbb.txt")
head(rio_txt)
# Excel XLSX
rio_xlsx <- import("mbb.xlsx")
head(rio_xlsx)
?View
View(rio_csv)
View(rio_txt)
View(rio_txt)
# Load a spreadsheet that has been saved as tab-delimited
# text file. Need to give complete address to file. This
# command gives an error on missing data but works on
# complete data.
r_txt1 <- read.table("~/Desktop/mbb.txt", header = TRUE)
# Load a spreadsheet that has been saved as tab-delimited
# text file. Need to give complete address to file. This
# command gives an error on missing data but works on
# complete data.
r_txt1 <- read.table("mbb.txt", header = TRUE)
# This works with missing data by specifying the separator:
# \t is for tabs, sep = "," for commas. R converts missing
# to "NA"
r_txt2 <- read.table("mbb.txt",
header = TRUE,
sep = "\t")
# CSV FILES
# Don't have to specify delimiters for missing data
# because CSV means "comma separated values"
trends.csv <- read.csv("mbb.csv", header = TRUE)
View(trends.csv)
View(trends.csv)
# Clear environment
rm(list = ls())
# Clear packages
p_unload(all)  # Remove all add-ons
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load base packages manually
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")
?mtcars
head(mtcars)
cars <- mtcars[, c(1:4, 6:7, 9:11)]  # Select variables
head(cars)
# Save hierarchical clustering to "hc." This codes uses
# pipes from dplyr.
hc <- cars   %>%  # Get cars data
dist   %>%  # Compute distance/dissimilarity matrix
hclust      # Computer hierarchical clusters
# Save hierarchical clustering to "hc." This codes uses
# pipes from dplyr.
hc <- cars   %>%  # Get cars data
dist   %>%  # Compute distance/dissimilarity matrix
hclust      # Computer hierarchical clusters
plot(hc)          # Plot dendrogram
library(datasets)  # Load base packages manually
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, tidyverse)
# Save hierarchical clustering to "hc." This codes uses
# pipes from dplyr.
hc <- cars   %>%  # Get cars data
dist   %>%  # Compute distance/dissimilarity matrix
hclust      # Computer hierarchical clusters
plot(hc)          # Plot dendrogram
rect.hclust(hc, k = 2, border = "gray")
rect.hclust(hc, k = 3, border = "blue")
rect.hclust(hc, k = 4, border = "green4")
rect.hclust(hc, k = 5, border = "darkred")
library(datasets)  # Load base packages manually
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, tidyverse)
head(mtcars)
cars <- mtcars[, c(1:4, 6:7, 9:11)]  # Select variables
head(cars)
# For entire data frame ####################################
pc <- prcomp(cars,
center = TRUE,  # Centers means to 0 (optional)
scale = TRUE)   # Sets unit variance (helpful)
pc <- prcomp(~ mpg + cyl + disp + hp + wt + qsec + am +
gear + carb,
data = mtcars,
center = TRUE,
scale = TRUE)
# Get summary stats
summary(pc)
# Screeplot for number of components
plot(pc)
# Get standard deviations and rotation
pc
# See how cases load on PCs
predict(pc) %>% round(2)
# Biplot of first two components
biplot(pc)
# Clear environment
rm(list = ls())
# Clear packages
p_unload(all)  # Remove all add-ons
detach("package:datasets", unload = TRUE)  # For base
# Clear plots
dev.off()  # But only if there IS a plot
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load base packages manually
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, caret, lars, tidyverse)
?USJudgeRatings
head(USJudgeRatings)
data <- USJudgeRatings
# Define variable groups
x <- as.matrix(data[, -12])
y <- data[, 12]
# Using variable groups
reg1 <- lm(y ~ x)
# Or specify variables individually
reg1 <- lm(RTEN ~ CONT + INTG + DMNR + DILG + CFMG +
DECI + PREP + FAMI + ORAL + WRIT + PHYS,
data = USJudgeRatings)
# Results
reg1           # Coefficients only
summary(reg1)  # Inferential tests
anova(reg1)            # Coefficients w/inferential tests
coef(reg1)             # Coefficients (same as reg1)
confint(reg1)          # CI for coefficients
resid(reg1)            # Residuals case-by-case
hist(residuals(reg1))  # Histogram of residuals
# Conventional stepwise regression
stepwise <- lars(x, y, type = "stepwise")
# Stagewise: Like stepwise but with better generalizability
forward <- lars(x, y, type = "forward.stagewise")
# LAR: Least Angle Regression
lar <- lars(x, y, type = "lar")
# LASSO: Least Absolute Shrinkage and Selection Operator
lasso <- lars(x, y, type = "lasso")
# Comparison of R^2 for new models
r2comp <- c(stepwise$R2[6], forward$R2[6],
lar$R2[6], lasso$R2[6]) %>%
round(2)
names(r2comp) <- c("stepwise", "forward", "lar", "lasso")
r2comp  # Show values of R^2
# CSV
eco_ind <- import("Output/compiled_z_scores.csv")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, rio)
# CSV
eco_ind <- import("Output/compiled_z_scores.csv")
setwd("C:/Users/srobi/Group_Projects/GeoLocation-Vs-Covid-Analysis-and-Visualization/sam")
# CSV
eco_ind <- import("Output/compiled_z_scores.csv")
# Clear environment
rm(list = ls())
# Clear packages
p_unload(all)  # Remove all add-ons
detach("package:datasets", unload = TRUE)  # For base
# Clear plots
dev.off()  # But only if there IS a plot
# Clear console
cat("\014")  # ctrl+L
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, rio)
# CSV
eco_ind <- import("Output/compiled_z_scores.csv")
head(eco_ind)
library(devtools)
install.packages("devtools")
install_github("")
install_github("nickpoison/astsa")
install.packages("devtools")
install_github("nickpoison/astsa")
devtools::install_github("r-lib/remotes")
devtools::install_github("nickpoison/astsa")
# eco_ind <- read.csv("economic_indicators.csv",header=True)
devtools::install_github("nickpoison/astsa")
install.Rtools(check=TRUE, check_r_update=TRUE)
install.Rtools(check=TRUE, check_r_update=TRUE)
install.packages(RTools)
install.packages(Rtools)
install.packages(Rtools4)
devtools::install_github("nickpoison/astsa")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, rio)
# CSV
eco_ind <- import("Output/compiled_z_scores.csv")
head(eco_ind)
# eco_ind <- read.csv("economic_indicators.csv",header=True)
devtools::install_github("nickpoison/astsa")
devtools::install_github("nickpoison/astsa/astsa_build")
# Use pacman to load add-on packages as desired
pacman::p_load(pacman, rio)
# CSV
eco_ind <- import("Output/compiled_z_scores.csv")
head(eco_ind)
# eco_ind <- read.csv("economic_indicators.csv",header=True)
devtools::install_github("nickpoison/astsa/astsa_build")
library(astsa)
# Install Packages
# example
# install.packages("oaColors")
# Install from github example
# devtools::install_github("nickpoison/astsa/astsa_build")
install.packages('forecast',dependencies=TRUE)
# Load Packages
# ex. library(oaColors)
library(astsa)
library(forecast)
head(eco_ind)
# Main code
astsa::lag2.plot(10-2_Z.ts,SP500_Z.ts,36)
10-2_Z.ts = ts(eco_ind$10-2_Z,start=c(2005,1), end=c(2021,8), frequency=12)
# Import Data
eco_ind <- import("Output/compiled_z_scores.csv")
head(eco_ind) # Display data
ten_two_Z.ts = ts(eco_ind$ten_two_Z,start=c(2005,1), end=c(2021,8), frequency=12)
ten_two_Z.ts = ts(eco_ind$ten_two_Z, start=c(2005,1), end=c(2021,8), frequency=12)
# Main code
plot(ten_two_Z.ts, xlab='Year', ylab='greenness', main='NDVI')
ten_two_Z.ts = ts(eco_ind$ten_two_Z, start=c(1990,1), end=c(2021,8), frequency=12)
# Import Data
# eco_ind <- import("Output/compiled_z_scores.csv")
eco_ind = read.csv('Output/compiled_z_scores.csv')
head(eco_ind) # Display data
ten_two_Z.ts = ts(eco_ind$ten_two_Z, start=c(1990,1), end=c(2021,8), frequency=12)
ten_two_Z.ts = ts(eco_ind$ten_two_Z, start=c(1990), end=c(2021), frequency=12)
ten_two_Z.ts = ts(eco_ind$ten_two_Z, start=c(1990), end=c(2021), frequency=4)
ten_two_Z.ts = ts(eco_ind$ten_two_Z, start=c(1990,1), end=c(2021,8), frequency=12)
randomData <- rnorm(100)
months.ts <-ts(randomData,start=2015,frequency=12)
randomData.head
head(randomData)
months.ts <-ts(randomData,start=2015,frequency=12)
quarter.ts <-ts(randomData,start=2015,frequency=4)
plot(months.ts)
plot(quarter.ts)
plot(months.ts)
plot(quarter.ts)
lines(months.ts,col=2)
months.ts <-ts(randomData,start=c(2015,6),frequency=12)
plot(months.ts)
plot(quarter.ts)
lines(months.ts,col=2)
ten_two_z.ts = ts(eco_ind$ten_two_z, start=c(1990,1), end=c(2021,8), frequency=12)
# Main code
plot(ten_two_z.ts, xlab='Year', ylab='greenness', main='NDVI')
head(ten_two_z.ts)
ten_two_z.ts = ts(eco_ind$ten_two_z, frequency=12)
head(ten_two_z.ts)
# Main code
plot(ten_two_z.ts, xlab='Year', ylab='greenness', main='NDVI')
ten_two_z.ts = ts(eco_ind$ten_two_z,start=c(1927,12) frequency=12)
# Main code
plot(ten_two_z.ts, xlab='Year', ylab='greenness', main='NDVI')
head(ten_two_z.ts)
ten_two_z.ts = ts(eco_ind$ten_two_z,start=c(1927,12), frequency=12)
head(ten_two_z.ts)
# Main code
plot(ten_two_z.ts, xlab='Year', ylab='greenness', main='NDVI')
# Main code
plot(ten_two_z.ts, xlab='Year', ylab='greenness', main='10-2 Treasury Spread Z-Scores')
# Main code
plot(ten_two_z.ts, xlab='Year', ylab='Z-Score', main='10-2 Treasury Spread Z-Scores')
abline(h=0.18)
abline(h=1)
abline(h=1.2)
# Main code
plot(ten_two_z.ts, xlab='Year', ylab='Z-Score', main='10-2 Treasury Spread Z-Scores')
abline(h=0)
lag.plot(ten_two_z.ts, lags=12, do.line=FALSE)
lag.plot(whitenoise, lags=12, do.line=FALSE)
acf(ten_two_z.ts)
